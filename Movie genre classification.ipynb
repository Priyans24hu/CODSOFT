{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1eccf8a-230c-4b98-8ee9-2d4d831e830e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\cp756\\anaconda3\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.65.4)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\cp756\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "!pip install tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ba62975-5b99-4201-9da1-8ea4fba79790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# File paths\n",
    "train_path = r'C:\\Users\\cp756\\OneDrive\\Desktop\\archive\\Genre Classification Dataset\\train_data.txt'\n",
    "test_path = r'C:\\Users\\cp756\\OneDrive\\Desktop\\archive\\Genre Classification Dataset\\test_data.txt'\n",
    "desc_path = r'C:\\Users\\cp756\\OneDrive\\Desktop\\archive\\Genre Classification Dataset\\description.txt'\n",
    "\n",
    "# Check if files exist\n",
    "if not all(map(os.path.exists, [train_path, test_path, desc_path])):\n",
    "    raise FileNotFoundError(\"One or more files were not found. Please check the file paths.\")\n",
    "\n",
    "try:\n",
    "    with open(train_path, 'r', encoding='utf-8') as train_file:\n",
    "        train_lines_new = train_file.readlines()\n",
    "        train_data = [line.strip().split(' ::: ') for line in train_lines_new]\n",
    "\n",
    "    with open(test_path, 'r', encoding='utf-8') as test_file:\n",
    "        test_lines_new = test_file.readlines()\n",
    "        test_data = [line.strip().split(' ::: ') for line in test_lines_new]\n",
    "\n",
    "    with open(desc_path, 'r', encoding='utf-8') as desc_file:\n",
    "        descriptions = desc_file.readlines()\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found: {e}\")\n",
    "except IOError as e:\n",
    "    print(f\"IO error occurred: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f68bb23-96c9-4604-b3a8-0a6a281aeecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_descriptions = [item[3] for item in train_data] + [item[2] for item in test_data] + descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b6da28b-28ef-477d-8691-23ca854ded75",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [item[2] for item in train_data] + [None for _ in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e89cdf1c-222c-4d45-b9cc-389c3b687a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54541614-9651-4d40-9236-fcc570ea83a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(all_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b5fec4d-419f-4e84-b898-23e26150c1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(all_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ed959eb-cbd8-4939-b39d-066f646cb984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pading sequences to a fixed length\n",
    "max_sequence_length = 100  # adjusting this based on our data\n",
    "sequences = pad_sequences(sequences, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ff2aba7-e7c9-4bfa-a4a2-264864f34621",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5107f002-bf2e-428a-9918-7d26aa3b5fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = sequences[:len(train_data)]\n",
    "test_sequences = sequences[len(train_data):len(train_data) + len(test_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb4dc974-0e0f-4cfc-8113-0be82023ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_sequences, encoded_labels[:len(train_data)], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fea97e1-f5ca-412a-aa36-4b5bceebd2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cp756\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=128, input_length=max_sequence_length))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4453162-edd1-4e0a-901b-a78f2900ed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1cd243f4-b8fe-4607-b410-c81a9f3c6c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cp756\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_5 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - accuracy: 0.2500 - loss: 1.1002\n",
      "Epoch 1: val_accuracy improved from -inf to 0.00000, saving model to C:\\Users\\cp756\\OneDrive\\Desktop\\archive\\Genre Classification Dataset\\movie_genre_classifier.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.2500 - loss: 1.1002 - val_accuracy: 0.0000e+00 - val_loss: 1.1331\n",
      "Epoch 2/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.2500 - loss: 1.1116\n",
      "Epoch 2: val_accuracy did not improve from 0.00000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.2500 - loss: 1.1116 - val_accuracy: 0.0000e+00 - val_loss: 1.1233\n",
      "Epoch 3/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5000 - loss: 1.0892\n",
      "Epoch 3: val_accuracy did not improve from 0.00000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.5000 - loss: 1.0892 - val_accuracy: 0.0000e+00 - val_loss: 1.1059\n",
      "Epoch 4/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5000 - loss: 1.0766\n",
      "Epoch 4: val_accuracy did not improve from 0.00000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5000 - loss: 1.0766 - val_accuracy: 0.0000e+00 - val_loss: 1.0992\n",
      "Epoch 5/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.5000 - loss: 1.0547\n",
      "Epoch 5: val_accuracy did not improve from 0.00000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.5000 - loss: 1.0547 - val_accuracy: 0.0000e+00 - val_loss: 1.0931\n",
      "Epoch 6/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5000 - loss: 1.0222\n",
      "Epoch 6: val_accuracy did not improve from 0.00000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.5000 - loss: 1.0222 - val_accuracy: 0.0000e+00 - val_loss: 1.0912\n",
      "Epoch 7/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5000 - loss: 1.0511\n",
      "Epoch 7: val_accuracy did not improve from 0.00000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5000 - loss: 1.0511 - val_accuracy: 0.0000e+00 - val_loss: 1.0957\n",
      "Epoch 8/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5000 - loss: 0.9978\n",
      "Epoch 8: val_accuracy did not improve from 0.00000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5000 - loss: 0.9978 - val_accuracy: 0.0000e+00 - val_loss: 1.1017\n",
      "Epoch 9/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5000 - loss: 1.0959\n",
      "Epoch 9: val_accuracy did not improve from 0.00000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5000 - loss: 1.0959 - val_accuracy: 0.0000e+00 - val_loss: 1.1137\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Best model saved at: C:\\Users\\cp756\\OneDrive\\Desktop\\archive\\Genre Classification Dataset\\movie_genre_classifier.keras\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.callbacks import  EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Sample data (you should replace this with your actual dataset)\n",
    "texts = [\n",
    "    \"This movie was great and thrilling\", \n",
    "    \"The film was boring and slow\", \n",
    "    \"An excellent horror movie with a gripping story\", \n",
    "    \"A terrible film with poor acting\", \n",
    "    \"A masterpiece of modern cinema\"\n",
    "]\n",
    "genres = [\"Action\", \"Drama\", \"Horror\", \"Drama\", \"Action\"]\n",
    "\n",
    "# Preprocessing\n",
    "max_words = 5000\n",
    "max_len = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "X = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "# One-hot encode the genre labels\n",
    "label_binarizer = LabelBinarizer()\n",
    "y = label_binarizer.fit_transform(genres)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the path to save the best model\n",
    "model_save_path = r'C:\\Users\\cp756\\OneDrive\\Desktop\\archive\\Genre Classification Dataset\\movie_genre_classifier.keras'\n",
    "\n",
    "# Create a ModelCheckpoint callback\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=model_save_path,\n",
    "    monitor='val_accuracy',    # Monitor validation accuracy\n",
    "    save_best_only=True,       # Save only the best model\n",
    "    mode='max',                # Maximize the monitored quantity\n",
    "    verbose=1                  # Verbosity mode (0 or 1)\n",
    ")\n",
    "\n",
    "# Create an EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',        # Monitor validation loss\n",
    "    patience=3,                # Number of epochs with no improvement before stopping\n",
    "    verbose=1,                 # Verbosity mode (0 or 1)\n",
    "    restore_best_weights=True  # Restore model weights from the best epoch\n",
    ")\n",
    "\n",
    "# List of callbacks to be used during training\n",
    "callbacks_list = [checkpoint, early_stopping]\n",
    "\n",
    "# Model architecture\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=128, input_length=max_len),  # Embedding layer\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),  # Bidirectional LSTM\n",
    "    Dropout(0.5),                                    # Dropout for regularization\n",
    "    LSTM(32),                                        # LSTM layer\n",
    "    Dropout(0.5),                                    # Dropout for regularization\n",
    "    Dense(y.shape[1], activation='softmax')          # Output layer for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),             # Adam optimizer\n",
    "    loss='categorical_crossentropy',                 # Loss function for multi-class classification\n",
    "    metrics=['accuracy']                             # Metrics to evaluate during training\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_data=(X_val, y_val),                  # Validation data\n",
    "    epochs=20,                                       # Number of training epochs\n",
    "    batch_size=32,                                   # Batch size\n",
    "    callbacks=callbacks_list                         # Use the ModelCheckpoint and EarlyStopping callbacks\n",
    ")\n",
    "\n",
    "# After training, the best model is saved at 'movie_genre_classifier.keras'\n",
    "print(f\"Best model saved at: {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "508cc576-8896-4cf0-aacd-f48ae530c1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.5000 - loss: 1.0878\n",
      "Epoch 1: val_accuracy did not improve from 0.00000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.5000 - loss: 1.0878 - val_accuracy: 0.0000e+00 - val_loss: 1.1399\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.5000 - loss: 1.0616\n",
      "Epoch 2: val_accuracy did not improve from 0.00000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.5000 - loss: 1.0616 - val_accuracy: 0.0000e+00 - val_loss: 1.1684\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.5000 - loss: 1.0611\n",
      "Epoch 3: val_accuracy did not improve from 0.00000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.5000 - loss: 1.0611 - val_accuracy: 0.0000e+00 - val_loss: 1.1990\n",
      "Epoch 3: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=epochs, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ee6a529-e05e-4fdc-8624-07be1701ad38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save(r'C:\\Users\\cp756\\OneDrive\\Desktop\\archive\\Genre Classification Dataset\\moviegenere.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0231aa1-96f7-4401-a5ce-f20038c0075e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model(r'C:\\Users\\cp756\\OneDrive\\Desktop\\archive\\Genre Classification Dataset\\moviegenere.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8d69ae6-6e6d-477a-9b87-69dcd58bfccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Predicted Genre: action\n"
     ]
    }
   ],
   "source": [
    "# Test the model with a sample movie summary\n",
    "movie_summary = [\" In The Secret Garden, a young girl named Mary, who is orphaned and lonely, discovers a hidden, neglected garden on her uncles estate. As she works to revive the garden, she also begins to heal emotionally and make new friends. This heartwarming story explores themes of growth, friendship, and the transformative power of nature.\"]\n",
    "movie_summary_sequence = tokenizer.texts_to_sequences(movie_summary)\n",
    "movie_summary_padded = pad_sequences(movie_summary_sequence, maxlen=max_sequence_length)\n",
    "predicted_label = loaded_model.predict(movie_summary_padded)\n",
    "\n",
    "predicted_genre = label_encoder.inverse_transform([np.argmax(predicted_label)])\n",
    "print(f\"Predicted Genre: {predicted_genre[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29922dd-780d-4438-acef-c4ff6e3daf89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
